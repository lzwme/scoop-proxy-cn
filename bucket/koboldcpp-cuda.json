{
  "version": "1.24",
  "description": "A simple one-file way to run various GGML models like LLAMA, ALPACA, VICUNA",
  "homepage": "https://github.com/LostRuins/koboldcpp",
  "license": "AGPL-3.0",
  "notes": "Look Mobel *.bin weights at https://rentry.org/nur779",
  "architecture": {
    "64bit": {
      "url": "https://ghproxy.net/https://github.com/LostRuins/koboldcpp/releases/download/v1.24/koboldcpp_CUDA_only.exe",
      "hash": "97DAE329FF496B044172AAA708BBAE2C98F3857D982F46E097E801A9BEFC7C87"
    }
  },
  "bin": "koboldcpp_CUDA_only.exe",
  "shortcuts": [
    [
      "koboldcpp_CUDA_only.exe",
      "KoboldCpp"
    ]
  ]
}